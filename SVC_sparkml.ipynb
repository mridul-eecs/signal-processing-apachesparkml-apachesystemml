{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVC_sparkml.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMRwMe8bRwH+N9FKdE5DTL6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mridul-eecs/signal-processing-apachesparkml-apachesystemml/blob/master/SVC_sparkml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L5px8-rm1Tv",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing to work with spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InunmNFxl1T3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "db8c5073-6392-4162-b5df-c5b6bdc0e9f5"
      },
      "source": [
        "\n",
        "# spark dependencies:\n",
        "# citation: http://medium.com/@rmache/big-data-with-spark-in-google-colab-7c046e24b3\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apachemirror.wuchna.com/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "\n",
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 56kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 47.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130387 sha256=88bfa1d6f4d3200b3adcef7e60ec95d1192aff052c3baf2fcabbbbbc8dd633ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5QOqyklmpnJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "00a6b893-92d8-4b5b-b269-7626462c7ca4"
      },
      "source": [
        "!git clone https://github.com/mridul-eecs/signal-processing-apachesparkml-apachesystemml.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'signal-processing-apachesparkml-apachesystemml'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Counting objects:   3% (1/31)\u001b[K\rremote: Counting objects:   6% (2/31)\u001b[K\rremote: Counting objects:   9% (3/31)\u001b[K\rremote: Counting objects:  12% (4/31)\u001b[K\rremote: Counting objects:  16% (5/31)\u001b[K\rremote: Counting objects:  19% (6/31)\u001b[K\rremote: Counting objects:  22% (7/31)\u001b[K\rremote: Counting objects:  25% (8/31)\u001b[K\rremote: Counting objects:  29% (9/31)\u001b[K\rremote: Counting objects:  32% (10/31)\u001b[K\rremote: Counting objects:  35% (11/31)\u001b[K\rremote: Counting objects:  38% (12/31)\u001b[K\rremote: Counting objects:  41% (13/31)\u001b[K\rremote: Counting objects:  45% (14/31)\u001b[K\rremote: Counting objects:  48% (15/31)\u001b[K\rremote: Counting objects:  51% (16/31)\u001b[K\rremote: Counting objects:  54% (17/31)\u001b[K\rremote: Counting objects:  58% (18/31)\u001b[K\rremote: Counting objects:  61% (19/31)\u001b[K\rremote: Counting objects:  64% (20/31)\u001b[K\rremote: Counting objects:  67% (21/31)\u001b[K\rremote: Counting objects:  70% (22/31)\u001b[K\rremote: Counting objects:  74% (23/31)\u001b[K\rremote: Counting objects:  77% (24/31)\u001b[K\rremote: Counting objects:  80% (25/31)\u001b[K\rremote: Counting objects:  83% (26/31)\u001b[K\rremote: Counting objects:  87% (27/31)\u001b[K\rremote: Counting objects:  90% (28/31)\u001b[K\rremote: Counting objects:  93% (29/31)\u001b[K\rremote: Counting objects:  96% (30/31)\u001b[K\rremote: Counting objects: 100% (31/31)\u001b[K\rremote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects:   4% (1/25)\u001b[K\rremote: Compressing objects:   8% (2/25)\u001b[K\rremote: Compressing objects:  12% (3/25)\u001b[K\rremote: Compressing objects:  16% (4/25)\u001b[K\rremote: Compressing objects:  20% (5/25)\u001b[K\rremote: Compressing objects:  24% (6/25)\u001b[K\rremote: Compressing objects:  28% (7/25)\u001b[K\rremote: Compressing objects:  32% (8/25)\u001b[K\rremote: Compressing objects:  36% (9/25)\u001b[K\rremote: Compressing objects:  40% (10/25)\u001b[K\rremote: Compressing objects:  44% (11/25)\u001b[K\rremote: Compressing objects:  48% (12/25)\u001b[K\rremote: Compressing objects:  52% (13/25)\u001b[K\rremote: Compressing objects:  56% (14/25)\u001b[K\rremote: Compressing objects:  60% (15/25)\u001b[K\rremote: Compressing objects:  64% (16/25)\u001b[K\rremote: Compressing objects:  68% (17/25)\u001b[K\rremote: Compressing objects:  72% (18/25)\u001b[K\rremote: Compressing objects:  76% (19/25)\u001b[K\rremote: Compressing objects:  80% (20/25)\u001b[K\rremote: Compressing objects:  84% (21/25)\u001b[K\rremote: Compressing objects:  88% (22/25)\u001b[K\rremote: Compressing objects:  92% (23/25)\u001b[K\rremote: Compressing objects:  96% (24/25)\u001b[K\rremote: Compressing objects: 100% (25/25)\u001b[K\rremote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "Unpacking objects:   3% (1/31)   \rUnpacking objects:   6% (2/31)   \rUnpacking objects:   9% (3/31)   \rUnpacking objects:  12% (4/31)   \rUnpacking objects:  16% (5/31)   \rUnpacking objects:  19% (6/31)   \rUnpacking objects:  22% (7/31)   \rUnpacking objects:  25% (8/31)   \rUnpacking objects:  29% (9/31)   \rUnpacking objects:  32% (10/31)   \rUnpacking objects:  35% (11/31)   \rUnpacking objects:  38% (12/31)   \rUnpacking objects:  41% (13/31)   \rUnpacking objects:  45% (14/31)   \rUnpacking objects:  48% (15/31)   \rUnpacking objects:  51% (16/31)   \rUnpacking objects:  54% (17/31)   \rUnpacking objects:  58% (18/31)   \rUnpacking objects:  61% (19/31)   \rUnpacking objects:  64% (20/31)   \rUnpacking objects:  67% (21/31)   \rUnpacking objects:  70% (22/31)   \rremote: Total 31 (delta 5), reused 16 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:  74% (23/31)   \rUnpacking objects:  77% (24/31)   \rUnpacking objects:  80% (25/31)   \rUnpacking objects:  83% (26/31)   \rUnpacking objects:  87% (27/31)   \rUnpacking objects:  90% (28/31)   \rUnpacking objects:  93% (29/31)   \rUnpacking objects:  96% (30/31)   \rUnpacking objects: 100% (31/31)   \rUnpacking objects: 100% (31/31), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYOzb0immrvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructField, StructType, IntegerType\n",
        "from pyspark.sql.functions import lit\n",
        "import os\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "APP_NAME= \"Human Motion Premitives\"\n",
        "SPARK_URL= \"local[*]\"\n",
        "RANDOM_SEED = 141109\n",
        "TRAINING_DATA_RATIO = 0.7\n",
        "RF_NUM_TREES = 8\n",
        "RF_MAX_DEPTH = 4\n",
        "RF_NUM_BINS = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZvR3LbdmuAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spark= SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SevzsyxSm8bI",
        "colab_type": "text"
      },
      "source": [
        "### Main program"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZpfmKxkqoNo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "64ed29b7-1b52-407f-e1e6-e7fc99ddd1dc"
      },
      "source": [
        "df= spark.read.parquet('/content/signal-processing-apachesparkml-apachesystemml/df.parquet')\n",
        "df.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+---+-------------+\n",
            "|  x|  y|  z|        class|\n",
            "+---+---+---+-------------+\n",
            "| 17| 46| 41|    Getup_bed|\n",
            "| 31| 41| 51|  Drink_glass|\n",
            "| 31| 41| 51|  Drink_glass|\n",
            "| 31| 41| 51|  Drink_glass|\n",
            "| 31| 41| 51|  Drink_glass|\n",
            "| 31| 41| 51|  Drink_glass|\n",
            "| 31| 41| 51|  Drink_glass|\n",
            "| 31| 41| 51|  Drink_glass|\n",
            "| 31| 41| 51|  Drink_glass|\n",
            "| 31| 41| 51|  Drink_glass|\n",
            "| 31| 41| 51|  Drink_glass|\n",
            "| 28| 41| 36|  Brush_teeth|\n",
            "| 34| 53| 33|         Walk|\n",
            "| 14| 46| 31|Standup_chair|\n",
            "| 18| 45| 36|Sitdown_chair|\n",
            "| 14| 26| 39|  Liedown_bed|\n",
            "| 28| 41| 48|         Walk|\n",
            "| 26| 52| 32|  Brush_teeth|\n",
            "| 26| 52| 32|  Brush_teeth|\n",
            "| 26| 52| 32|  Brush_teeth|\n",
            "+---+---+---+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm0lVDhY0QJK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "034bfec9-c51e-4f67-ba21-c40a383c96dd"
      },
      "source": [
        "## As linear SVC supports binary class only, dropping all classes except 2\n",
        "print(df.count())\n",
        "classes= spark.sql(\"\"\"select df.class from df\"\"\")\n",
        "classcounts= spark.sql(\"\"\"select class, count(*) from df group by class\"\"\")\n",
        "class_list= classes.distinct().collect()\n",
        "class_list= [i[0] for i in class_list]\n",
        "print(class_list)\n",
        "\n",
        "newdf= spark.sql(\"\"\"select * from df where df.class= 'Use_telephone' or df.class = 'Standup_chair'\"\"\")\n",
        "newdf.show()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "446529\n",
            "['Use_telephone', 'Standup_chair', 'Eat_meat', 'Getup_bed', 'Drink_glass', 'Pour_water', 'Comb_hair', 'Walk', 'Climb_stairs', 'Sitdown_chair', 'Liedown_bed', 'Descend_stairs', 'Brush_teeth', 'Eat_soup']\n",
            "+---+---+---+-------------+\n",
            "|  x|  y|  z|        class|\n",
            "+---+---+---+-------------+\n",
            "| 14| 46| 31|Standup_chair|\n",
            "| 49| 24| 40|Use_telephone|\n",
            "|  7| 30| 17|Standup_chair|\n",
            "| 16| 41| 44|Standup_chair|\n",
            "| 34| 43| 44|Use_telephone|\n",
            "| 14| 40| 33|Standup_chair|\n",
            "| 14| 40| 33|Standup_chair|\n",
            "| 14| 40| 33|Standup_chair|\n",
            "| 14| 40| 33|Standup_chair|\n",
            "| 14| 40| 33|Standup_chair|\n",
            "| 14| 40| 33|Standup_chair|\n",
            "| 14| 40| 33|Standup_chair|\n",
            "| 44| 31| 50|Use_telephone|\n",
            "| 44| 31| 50|Use_telephone|\n",
            "| 12| 30| 33|Standup_chair|\n",
            "| 29| 41| 51|Standup_chair|\n",
            "| 29| 41| 51|Standup_chair|\n",
            "| 29| 41| 51|Standup_chair|\n",
            "| 29| 41| 51|Standup_chair|\n",
            "| 25| 36| 44|Use_telephone|\n",
            "+---+---+---+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_kN5OZ1qoIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df= df.createOrReplaceTempView('df')\n",
        "train_df, test_df= newdf.randomSplit([0.8, 0.2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysZPq9ZHmvk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, Normalizer\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "from pyspark.ml.classification import LinearSVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6ZT5N5yqdyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indexer= StringIndexer(inputCol= 'class', outputCol= 'label')\n",
        "vectorizer= VectorAssembler(inputCols= ['x', 'y', 'z'], outputCol= 'feat')\n",
        "normalizer= Normalizer(inputCol= 'feat', outputCol= 'features', p=1.0) \n",
        "\n",
        "\n",
        "svmc= LinearSVC(maxIter=100, regParam= 0.1)\n",
        "pipe= Pipeline(stages= [indexer, vectorizer, normalizer, svmc])#, svmc])\n",
        "model= pipe.fit(train_df)\n",
        "predx= model.transform(train_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V82-iQcuyYSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "501c6edf-438b-41e1-e2e7-5e6ed0961767"
      },
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "evaluator= BinaryClassificationEvaluator(rawPredictionCol= 'rawPrediction')\n",
        "evaluator.evaluate(predx)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9436969698242931"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb1aftdd__C8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aefaec0b-05e2-44f6-d5f3-fa700065c2a7"
      },
      "source": [
        "predy= model.transform(test_df)\n",
        "evaluator.evaluate(predy)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9463875981233855"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "601JbvWoGsXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}