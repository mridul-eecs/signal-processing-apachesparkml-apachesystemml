{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KmeansSparkML.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyORz00yoC5K1/iDuIdvaMZR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mridul-eecs/signal-processing-apachesparkml-apachesystemml/blob/master/KmeansSparkML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L5px8-rm1Tv",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing to work with spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InunmNFxl1T3",
        "colab_type": "code",
        "outputId": "06382c23-86fc-48a1-9854-75669df7cea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "source": [
        "\n",
        "# spark dependencies:\n",
        "# citation: http://medium.com/@rmache/big-data-with-spark-in-google-colab-7c046e24b3\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apachemirror.wuchna.com/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "\n",
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 61kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 49.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130387 sha256=509b28298180f529865da2c474e39e54e07fd3ea8833dc8947c7232be7542392\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5QOqyklmpnJ",
        "colab_type": "code",
        "outputId": "066ae42b-37b0-4747-ad9b-1f09f9a77395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "!git clone https://github.com/mridul-eecs/signal-processing-apachesparkml-apachesystemml.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'signal-processing-apachesparkml-apachesystemml'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/44)\u001b[K\rremote: Counting objects:   4% (2/44)\u001b[K\rremote: Counting objects:   6% (3/44)\u001b[K\rremote: Counting objects:   9% (4/44)\u001b[K\rremote: Counting objects:  11% (5/44)\u001b[K\rremote: Counting objects:  13% (6/44)\u001b[K\rremote: Counting objects:  15% (7/44)\u001b[K\rremote: Counting objects:  18% (8/44)\u001b[K\rremote: Counting objects:  20% (9/44)\u001b[K\rremote: Counting objects:  22% (10/44)\u001b[K\rremote: Counting objects:  25% (11/44)\u001b[K\rremote: Counting objects:  27% (12/44)\u001b[K\rremote: Counting objects:  29% (13/44)\u001b[K\rremote: Counting objects:  31% (14/44)\u001b[K\rremote: Counting objects:  34% (15/44)\u001b[K\rremote: Counting objects:  36% (16/44)\u001b[K\rremote: Counting objects:  38% (17/44)\u001b[K\rremote: Counting objects:  40% (18/44)\u001b[K\rremote: Counting objects:  43% (19/44)\u001b[K\rremote: Counting objects:  45% (20/44)\u001b[K\rremote: Counting objects:  47% (21/44)\u001b[K\rremote: Counting objects:  50% (22/44)\u001b[K\rremote: Counting objects:  52% (23/44)\u001b[K\rremote: Counting objects:  54% (24/44)\u001b[K\rremote: Counting objects:  56% (25/44)\u001b[K\rremote: Counting objects:  59% (26/44)\u001b[K\rremote: Counting objects:  61% (27/44)\u001b[K\rremote: Counting objects:  63% (28/44)\u001b[K\rremote: Counting objects:  65% (29/44)\u001b[K\rremote: Counting objects:  68% (30/44)\u001b[K\rremote: Counting objects:  70% (31/44)\u001b[K\rremote: Counting objects:  72% (32/44)\u001b[K\rremote: Counting objects:  75% (33/44)\u001b[K\rremote: Counting objects:  77% (34/44)\u001b[K\rremote: Counting objects:  79% (35/44)\u001b[K\rremote: Counting objects:  81% (36/44)\u001b[K\rremote: Counting objects:  84% (37/44)\u001b[K\rremote: Counting objects:  86% (38/44)\u001b[K\rremote: Counting objects:  88% (39/44)\u001b[K\rremote: Counting objects:  90% (40/44)\u001b[K\rremote: Counting objects:  93% (41/44)\u001b[K\rremote: Counting objects:  95% (42/44)\u001b[K\rremote: Counting objects:  97% (43/44)\u001b[K\rremote: Counting objects: 100% (44/44)\u001b[K\rremote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects:   2% (1/38)\u001b[K\rremote: Compressing objects:   5% (2/38)\u001b[K\rremote: Compressing objects:   7% (3/38)\u001b[K\rremote: Compressing objects:  10% (4/38)\u001b[K\rremote: Compressing objects:  13% (5/38)\u001b[K\rremote: Compressing objects:  15% (6/38)\u001b[K\rremote: Compressing objects:  18% (7/38)\u001b[K\rremote: Compressing objects:  21% (8/38)\u001b[K\rremote: Compressing objects:  23% (9/38)\u001b[K\rremote: Compressing objects:  26% (10/38)\u001b[K\rremote: Compressing objects:  28% (11/38)\u001b[K\rremote: Compressing objects:  31% (12/38)\u001b[K\rremote: Compressing objects:  34% (13/38)\u001b[K\rremote: Compressing objects:  36% (14/38)\u001b[K\rremote: Compressing objects:  39% (15/38)\u001b[K\rremote: Compressing objects:  42% (16/38)\u001b[K\rremote: Compressing objects:  44% (17/38)\u001b[K\rremote: Compressing objects:  47% (18/38)\u001b[K\rremote: Compressing objects:  50% (19/38)\u001b[K\rremote: Compressing objects:  52% (20/38)\u001b[K\rremote: Compressing objects:  55% (21/38)\u001b[K\rremote: Compressing objects:  57% (22/38)\u001b[K\rremote: Compressing objects:  60% (23/38)\u001b[K\rremote: Compressing objects:  63% (24/38)\u001b[K\rremote: Compressing objects:  65% (25/38)\u001b[K\rremote: Compressing objects:  68% (26/38)\u001b[K\rremote: Compressing objects:  71% (27/38)\u001b[K\rremote: Compressing objects:  73% (28/38)\u001b[K\rremote: Compressing objects:  76% (29/38)\u001b[K\rremote: Compressing objects:  78% (30/38)\u001b[K\rremote: Compressing objects:  81% (31/38)\u001b[K\rremote: Compressing objects:  84% (32/38)\u001b[K\rremote: Compressing objects:  86% (33/38)\u001b[K\rremote: Compressing objects:  89% (34/38)\u001b[K\rremote: Compressing objects:  92% (35/38)\u001b[K\rremote: Compressing objects:  94% (36/38)\u001b[K\rremote: Compressing objects:  97% (37/38)\u001b[K\rremote: Compressing objects: 100% (38/38)\u001b[K\rremote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "Unpacking objects:   2% (1/44)   \rUnpacking objects:   4% (2/44)   \rUnpacking objects:   6% (3/44)   \rUnpacking objects:   9% (4/44)   \rUnpacking objects:  11% (5/44)   \rUnpacking objects:  13% (6/44)   \rUnpacking objects:  15% (7/44)   \rUnpacking objects:  18% (8/44)   \rUnpacking objects:  20% (9/44)   \rUnpacking objects:  22% (10/44)   \rUnpacking objects:  25% (11/44)   \rUnpacking objects:  27% (12/44)   \rUnpacking objects:  29% (13/44)   \rUnpacking objects:  31% (14/44)   \rUnpacking objects:  34% (15/44)   \rUnpacking objects:  36% (16/44)   \rUnpacking objects:  38% (17/44)   \rUnpacking objects:  40% (18/44)   \rUnpacking objects:  43% (19/44)   \rUnpacking objects:  45% (20/44)   \rUnpacking objects:  47% (21/44)   \rUnpacking objects:  50% (22/44)   \rUnpacking objects:  52% (23/44)   \rUnpacking objects:  54% (24/44)   \rUnpacking objects:  56% (25/44)   \rUnpacking objects:  59% (26/44)   \rUnpacking objects:  61% (27/44)   \rUnpacking objects:  63% (28/44)   \rUnpacking objects:  65% (29/44)   \rUnpacking objects:  68% (30/44)   \rUnpacking objects:  70% (31/44)   \rremote: Total 44 (delta 12), reused 16 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:  72% (32/44)   \rUnpacking objects:  75% (33/44)   \rUnpacking objects:  77% (34/44)   \rUnpacking objects:  79% (35/44)   \rUnpacking objects:  81% (36/44)   \rUnpacking objects:  84% (37/44)   \rUnpacking objects:  86% (38/44)   \rUnpacking objects:  88% (39/44)   \rUnpacking objects:  90% (40/44)   \rUnpacking objects:  93% (41/44)   \rUnpacking objects:  95% (42/44)   \rUnpacking objects:  97% (43/44)   \rUnpacking objects: 100% (44/44)   \rUnpacking objects: 100% (44/44), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYOzb0immrvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructField, StructType, IntegerType\n",
        "from pyspark.sql.functions import lit\n",
        "import os\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "APP_NAME= \"Human Motion Premitives\"\n",
        "SPARK_URL= \"local[*]\"\n",
        "RANDOM_SEED = 141109\n",
        "TRAINING_DATA_RATIO = 0.7\n",
        "RF_NUM_TREES = 8\n",
        "RF_MAX_DEPTH = 4\n",
        "RF_NUM_BINS = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZvR3LbdmuAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spark= SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SevzsyxSm8bI",
        "colab_type": "text"
      },
      "source": [
        "### Main program"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ3dXOax-15U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datapath= '/content/signal-processing-apachesparkml-apachesystemml/df.parquet'\n",
        "df= spark.read.parquet(datapath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AVuNAce9_Eh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler, Normalizer\n",
        "\n",
        "vectorizer= VectorAssembler(inputCols= ['x', 'y', 'z'], outputCol= 'features')\n",
        "kmeans= KMeans().setK(13).setSeed(1)\n",
        "pipe= Pipeline(stages= [vectorizer, kmeans])\n",
        "\n",
        "model= pipe.fit(df)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4ZsjsT4_EkW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0326a286-5dd3-49b3-9b23-2db72e6be7dc"
      },
      "source": [
        "model.transform(df)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[x: int, y: int, z: int, class: string, features: vector, prediction: int]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsEGs0pSGTU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wssse= model.stages[-1].computeCost(vectorizer.transform(df))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17a20Q84Ggyf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c48aff7f-442e-4516-85d7-86bc73c947dd"
      },
      "source": [
        "print(wssse)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15827497.774103818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qxkMqS6GocG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "edae99f6-c361-476a-e873-3ddcff32c96d"
      },
      "source": [
        "# considering only 2 classes \n",
        "df= df.createOrReplaceTempView('df')\n",
        "bindf= spark.sql(\"\"\"select * from df where df.class in ('Use_telephone', 'Standup_chair')\"\"\")\n",
        "bindf.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+---+-------------+\n",
            "|  x|  y|  z|        class|\n",
            "+---+---+---+-------------+\n",
            "| 14| 46| 31|Standup_chair|\n",
            "| 49| 24| 40|Use_telephone|\n",
            "|  7| 30| 17|Standup_chair|\n",
            "| 16| 41| 44|Standup_chair|\n",
            "| 34| 43| 44|Use_telephone|\n",
            "| 14| 40| 33|Standup_chair|\n",
            "| 14| 40| 33|Standup_chair|\n",
            "| 14| 40| 33|Standup_chair|\n",
            "| 14| 40| 33|Standup_chair|\n",
            "| 14| 40| 33|Standup_chair|\n",
            "| 14| 40| 33|Standup_chair|\n",
            "| 14| 40| 33|Standup_chair|\n",
            "| 44| 31| 50|Use_telephone|\n",
            "| 44| 31| 50|Use_telephone|\n",
            "| 12| 30| 33|Standup_chair|\n",
            "| 29| 41| 51|Standup_chair|\n",
            "| 29| 41| 51|Standup_chair|\n",
            "| 29| 41| 51|Standup_chair|\n",
            "| 29| 41| 51|Standup_chair|\n",
            "| 25| 36| 44|Use_telephone|\n",
            "+---+---+---+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO9Nj78oHDVL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd32bca8-d4ba-43f9-ff72-a792223d6651"
      },
      "source": [
        "vectorizer= VectorAssembler(inputCols= ['x', 'y', 'z'], outputCol= 'features')\n",
        "kmeans= KMeans().setK(2).setSeed(1)\n",
        "pipe= Pipeline(stages= [vectorizer, kmeans])\n",
        "\n",
        "model= pipe.fit(bindf)\n",
        "pred= model.transform(bindf)\n",
        "model.stages[-1].computeCost(vectorizer.transform(bindf))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4478194.572658991"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2tNoYEEH6ne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}